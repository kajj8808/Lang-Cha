{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model IO\n",
    "모델 I/O 모듈에는 입력(input)과 출력(output)이 있음.\n",
    "입력과 출력의 뜻으로 input은 우선 prompt(명령 등을 내리는 곳)임. (Prompts, Language models, Output parser 등이 있음.)\n",
    "\n",
    "## Retrueval (리트리블)\n",
    "- Retrueval은 `외부 데이터`로 접근하여 이를 모델에 `어떻게 제공`하는 것에 관한 거임.\n",
    "- document loaders, Transformers, text embedding , vector stores , retrievers 등이 있음.\n",
    "- 이것들 전부 우리의 데이터들로 작업하게 하고 모델에게 제공할 수 있는지에 관한 거임. ( 대충 외부 데이터를 가지고 모델과 작업하는 부분 )\n",
    "\n",
    "## Chains\n",
    "- 이전에 했던 내용. ( 나중에 자세히 작성 )\n",
    "\n",
    "## Agents \n",
    "- `독립적으로 AI가 작동하도록 만들 수 있게 해주는 agents`.\n",
    "- chains이 필요한 도구들을 선택하여 사용할 수 있도록 해줌.\n",
    "- 그냥 chains에게 일을 맞기고 그에 맞는 커스텀 도구를 만들어 준다면 chains 스스로 사용할 tool들을 선택함...(?)\n",
    "\n",
    "## Memory (기억)\n",
    "- 챗봇에 Memory(기억)할 수 있도록 하는 것.\n",
    "\n",
    "## Callbacks \n",
    "- callbacks는 기본적으로 model이 무엇을 하고 있는지, 중간에 알 수 있도록 하는 것. ( intermediate )\n",
    "- 모델이 답변을 제공하기 전에 모델이 어떤 일을 하고 있는지 확인 할 수 있음. (무엇을 생각하고 있는지.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of France'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Template 처리.\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "template = PromptTemplate.from_template(\"What is the capital of {country}\")\n",
    "\n",
    "template.format(country=\"France\")\n",
    "# template.format() # <- error(필수 적인 값 France이 없기 떄문)\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template=\"What is the capital of {country}\",\n",
    "    input_variables=[\"country\"]\n",
    ") # 이렇게도 가능.\n",
    "\n",
    "template.format(country=\"France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "I know this:\n",
      "Capital: Seoul\n",
      "Language: Korean\n",
      "Food: Kimchi and Bibimbap\n",
      "Currency: South Korean Won"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI: \\nI know this:\\nCapital: Seoul\\nLanguage: Korean\\nFood: Kimchi and Bibimbap\\nCurrency: South Korean Won')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FewShotPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "# 미리 대답해 놓은 예시\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "Here is what I know:\n",
    "Capital: Paris\n",
    "Language: French\n",
    "Food: Wine and Cheese\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "I know this:\n",
    "Capital: Rome\n",
    "Language: Italian\n",
    "Food: Pizza and Pasta\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "I know this:\n",
    "Capital: Athens\n",
    "Language: Greek\n",
    "Food: Souvlaki and Feta Cheese\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "    Human: {question}\n",
    "    AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "# example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\") ## same\n",
    "\n",
    "# 랭체인이 알아서 각각의 예제 리스트들을 prompt를 사용해서 형식화 할꺼임.\n",
    "# question , answer 값으로 -> `이건 다르게 넣으면 안됨!`\n",
    "# suffix는 형식화가 끝난 후 마지막에 나오는 거임.\n",
    "# suffix에서 어떤 변수를 사용해야하는지 input_variables에 작성해 줘야함.\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "# prompt.format(country=\"Korea\")\n",
    "# 이렇게 해주면, 이제 어떻게 대답해야 하는지에 대한 형식을 알아서 형식에 맞게 대답해줌.! 대충 예제를 가져오고 예제를 prompt로 형식화 하고( 오브젝트 이름에 맞게 설정! example_template 참조.. ) \n",
    "# 그리고 형식화 된 값을 FewShot에게 전달해주기만 해도 양식에 맞춰서 대답해줌.. good..\n",
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\" : \"Korea\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FewShotPromptTemplate , Fewshot Learning\n",
    "- `Fewshot은 모델에게 예제를 준다는 뜻과 같음.`\n",
    "- 더 나은 대답을 할 수 있도록 하는 예제를 줄 수 있음.\n",
    "- 복잡한 대답을 원할 경우 모델에게 `어떻게 대답해야 하는 지에 대한 예제를 AI모델에게 주는게(Fewshot) prompt를 사용해서 어떻게 대답해야 하는지 알려주는 것보다 훨씬 좋음.`\n",
    "- 예를 들어 모델에게 콤마(,)를 써서 구분해줘, 소문자만 써야해 등... ( 모델이 text를 생성하기에 어떻게 대답해야 하는지에 대한 예시를 미리 주는게 더 좋은 방식임! `생성하기 전에 예시를 줌!` 생성 할 경우에 주는게 아니라! )\n",
    "- 만약 고객지원 봇을 만들때 이전 데이터( 이전에 운영 했을 경우 )가 있을 경우 많은 고객들과 대화 기록이 남아 있을 것임. 그럼 language model에게 어떻게 말해야 할지(대응 해야할지)에 대해 알려주고 싶을꺼임.(많은 데이터가 있기 때문에) 그럼 그냥 대화 내용을 가져와서 형식화 시켜주면 더 잘 만들 수 있을것임.\n",
    "- `FewShotPromptTemplate`은 형식을 주고 그 형식대로 만들어 돌라는 것을 하는거임! 엄청난 기능!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
