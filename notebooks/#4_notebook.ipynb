{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model IO\n",
    "모델 I/O 모듈에는 입력(input)과 출력(output)이 있음.\n",
    "입력과 출력의 뜻으로 input은 우선 prompt(명령 등을 내리는 곳)임. (Prompts, Language models, Output parser 등이 있음.)\n",
    "\n",
    "## Retrueval (리트리블)\n",
    "- Retrueval은 `외부 데이터`로 접근하여 이를 모델에 `어떻게 제공`하는 것에 관한 거임.\n",
    "- document loaders, Transformers, text embedding , vector stores , retrievers 등이 있음.\n",
    "- 이것들 전부 우리의 데이터들로 작업하게 하고 모델에게 제공할 수 있는지에 관한 거임. ( 대충 외부 데이터를 가지고 모델과 작업하는 부분 )\n",
    "\n",
    "## Chains\n",
    "- 이전에 했던 내용. ( 나중에 자세히 작성 )\n",
    "\n",
    "## Agents \n",
    "- `독립적으로 AI가 작동하도록 만들 수 있게 해주는 agents`.\n",
    "- chains이 필요한 도구들을 선택하여 사용할 수 있도록 해줌.\n",
    "- 그냥 chains에게 일을 맞기고 그에 맞는 커스텀 도구를 만들어 준다면 chains 스스로 사용할 tool들을 선택함...(?)\n",
    "\n",
    "## Memory (기억)\n",
    "- 챗봇에 Memory(기억)할 수 있도록 하는 것.\n",
    "\n",
    "## Callbacks \n",
    "- callbacks는 기본적으로 model이 무엇을 하고 있는지, 중간에 알 수 있도록 하는 것. ( intermediate )\n",
    "- 모델이 답변을 제공하기 전에 모델이 어떤 일을 하고 있는지 확인 할 수 있음. (무엇을 생각하고 있는지.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of France'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Template 처리.\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "template = PromptTemplate.from_template(\"What is the capital of {country}\")\n",
    "\n",
    "template.format(country=\"France\")\n",
    "# template.format() # <- error(필수 적인 값 France이 없기 떄문)\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template=\"What is the capital of {country}\",\n",
    "    input_variables=[\"country\"]\n",
    ") # 이렇게도 가능.\n",
    "\n",
    "template.format(country=\"France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "I know this:\n",
      "Capital: Seoul\n",
      "Language: Korean\n",
      "Food: Kimchi and Bibimbap\n",
      "Currency: South Korean Won"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI: \\nI know this:\\nCapital: Seoul\\nLanguage: Korean\\nFood: Kimchi and Bibimbap\\nCurrency: South Korean Won')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FewShotPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "# 미리 대답해 놓은 예시\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "Here is what I know:\n",
    "Capital: Paris\n",
    "Language: French\n",
    "Food: Wine and Cheese\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "I know this:\n",
    "Capital: Rome\n",
    "Language: Italian\n",
    "Food: Pizza and Pasta\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "I know this:\n",
    "Capital: Athens\n",
    "Language: Greek\n",
    "Food: Souvlaki and Feta Cheese\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "example_template = \"\"\"\n",
    "    Human: {question}\n",
    "    AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "# example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\") ## same\n",
    "\n",
    "# 랭체인이 알아서 각각의 예제 리스트들을 prompt를 사용해서 형식화 할꺼임.\n",
    "# question , answer 값으로 -> `이건 다르게 넣으면 안됨!`\n",
    "# suffix는 형식화가 끝난 후 마지막에 나오는 거임.\n",
    "# suffix에서 어떤 변수를 사용해야하는지 input_variables에 작성해 줘야함.\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "# prompt.format(country=\"Korea\")\n",
    "# 이렇게 해주면, 이제 어떻게 대답해야 하는지에 대한 형식을 알아서 형식에 맞게 대답해줌.! 대충 예제를 가져오고 예제를 prompt로 형식화 하고( 오브젝트 이름에 맞게 설정! example_template 참조.. ) \n",
    "# 그리고 형식화 된 값을 FewShot에게 전달해주기만 해도 양식에 맞춰서 대답해줌.. good..\n",
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\" : \"Korea\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FewShotPromptTemplate , Fewshot Learning\n",
    "- `Fewshot은 모델에게 예제를 준다는 뜻과 같음.`\n",
    "- 더 나은 대답을 할 수 있도록 하는 예제를 줄 수 있음.\n",
    "- 복잡한 대답을 원할 경우 모델에게 `어떻게 대답해야 하는 지에 대한 예제를 AI모델에게 주는게(Fewshot) prompt를 사용해서 어떻게 대답해야 하는지 알려주는 것보다 훨씬 좋음.`\n",
    "- 예를 들어 모델에게 콤마(,)를 써서 구분해줘, 소문자만 써야해 등... ( 모델이 text를 생성하기에 어떻게 대답해야 하는지에 대한 예시를 미리 주는게 더 좋은 방식임! `생성하기 전에 예시를 줌!` 생성 할 경우에 주는게 아니라! )\n",
    "- 만약 고객지원 봇을 만들때 이전 데이터( 이전에 운영 했을 경우 )가 있을 경우 많은 고객들과 대화 기록이 남아 있을 것임. 그럼 language model에게 어떻게 말해야 할지(대응 해야할지)에 대해 알려주고 싶을꺼임.(많은 데이터가 있기 때문에) 그럼 그냥 대화 내용을 가져와서 형식화 시켜주면 더 잘 만들 수 있을것임.\n",
    "- `FewShotPromptTemplate`은 형식을 주고 그 형식대로 만들어 돌라는 것을 하는거임! 엄청난 기능!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I know this:\n",
      "Capital: Seoul\n",
      "Language: Korean\n",
      "Food: Kimchi and Bibimbap\n",
      "Currency: South Korean Won"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='\\nI know this:\\nCapital: Seoul\\nLanguage: Korean\\nFood: Kimchi and Bibimbap\\nCurrency: South Korean Won')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "# 미리 대답해 놓은 예시\n",
    "examples = [\n",
    "    {\n",
    "        \"country\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "Here is what I know:\n",
    "Capital: Paris\n",
    "Language: French\n",
    "Food: Wine and Cheese\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "I know this:\n",
    "Capital: Rome\n",
    "Language: Italian\n",
    "Food: Pizza and Pasta\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Greece\",\n",
    "        \"answer\": \"\"\"\n",
    "I know this:\n",
    "Capital: Athens\n",
    "Language: Greek\n",
    "Food: Souvlaki and Feta Cheese\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# 다른 부분.\n",
    "# AI에게 \"너 이런식으로 답변했었어.\" \n",
    "# 으로 답변하게 만들려고 AI를 속이고 있는 방식.\n",
    "# 예제를 형식화 하기 위한것. -> 실제 메세지 x 오직 형식화. 밑에서 형식으로 변환!\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"What do you know about {country}?\"),\n",
    "    (\"ai\", \"{answer}\")\n",
    "])\n",
    "# example_prompt(이전에 이렇게 답했어.)대답 양식을 이용한 fewshot생성\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "# 이전에 답했던?(example_prompt)를 이용해서 chat처럼 답하게 작성.\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you are a geography expert. you give short answers.\"),\n",
    "    example_prompt,\n",
    "    (\"human\", \"What do you know about {country}?\"),\n",
    "])\n",
    "\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\": \"South Korea\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What do you know about Italy?\n",
      "AI: \n",
      "        I know this:\n",
      "        Capital: Rome\n",
      "        Language: Italian\n",
      "        Food: Pizza and Pasta\n",
      "        Currency: Euro\n",
      "        \n",
      "\n",
      "Human: What do you know about south korea?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' chain = prompt | chat\\n\\nchain.invoke({\\n    \"country\": \"Korea\"\\n}) '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length Based Example Selector\n",
    "# sample이 많아지는 경우가 있어, 어느 정도의 example들을 골라서 prompt에 허용할건지 정해야하는 경우에 사용.\n",
    "\n",
    "from typing import Any, Dict, List\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "# 미리 대답해 놓은 예시\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# 예제 선택기를 만드는 방법!. BaseExampleSelector를 가져와서 만들면됨. \n",
    "# 부족한 부분은 이거 만들어야 된다 error 출력됨.. ! 굿..\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "        return [choice(self.examples)]\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\n",
    "    \"Human: {question}\\nAI: {answer}\")\n",
    "\n",
    "example_selector = RandomExampleSelector(\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "\"\"\" example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=80\n",
    ")\n",
    " \"\"\"\n",
    "# print(example_selector.example_text_lengths)\n",
    "# [73, 71, 72] 가 나오는데 80 제한이라 하나만 가져와 지는것.! 예제들의 크기 가 합산임!\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "print(prompt.format(country=\"south korea\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrrrg! Me favorite food be a hearty stew made with fresh seafood and plenty of spices! Arrrrg! Nothing like a good meal to keep me strength up for plunderin' the high seas! Arrrrg!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"Arrrrg! Me favorite food be a hearty stew made with fresh seafood and plenty of spices! Arrrrg! Nothing like a good meal to keep me strength up for plunderin' the high seas! Arrrrg!\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialization and Composition\n",
    "# prompt를 어디 저장하고 다른 누구나 플롬포트를 가져다 쓸 수 있도록 하고 싶은 경우.\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "# json\n",
    "# prompt = load_prompt(\"../prompt.json\")\n",
    "\n",
    "# yaml\n",
    "# prompt = load_prompt(\"../prompt.yaml\")\n",
    "# prompt.format(country=\"south korea\")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant.\n",
    "    And you are impersonating a {character}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    This is an example of how you talk:\n",
    "\n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "\n",
    "    Human: {question}\n",
    "    You:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "                                     \n",
    "    {example}\n",
    "                              \n",
    "    {start}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\", start)\n",
    "]\n",
    "# 여러개의 prompt들을 하나의 prompt로 합치는 방법.\n",
    "full_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=final,\n",
    "    pipeline_prompts=prompts,\n",
    ")\n",
    "\n",
    "# format test임! \n",
    "full_prompt.format(\n",
    "    character=\"Pirate\",\n",
    "    example_question=\"What is your location?\",\n",
    "    example_answer=\"Arrrrrrg! That is a secret!!! Arrrrg! Arrrrg!\",\n",
    "    question=\"What is your fav food?\",\n",
    ")\n",
    "\n",
    "chain = full_prompt | chat\n",
    "chain.invoke({\n",
    "    \"character\": \"Pirate\",\n",
    "    \"example_question\": \"What is your location?\",\n",
    "    \"example_answer\": \"Arrrrrrg! That is a secret!!! Arrrrg! Arrrrg!\",\n",
    "    \"question\": \"What is your fav food?\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
